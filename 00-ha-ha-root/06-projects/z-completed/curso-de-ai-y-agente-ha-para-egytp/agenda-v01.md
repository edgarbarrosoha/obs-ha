### **Session 1 ‚Äî The AI Landscape: How We Got Here (1.5 hrs)**

**Goal:** Establish a shared foundation of understanding about generative AI.  
**Content:**

- The evolution of AI and the rise of large language models (LLMs).
    
- The educational ecosystem: ChatGPT Edu, Claude for Education, Gemini for Education.
    
- Algorithms vs. Models: understanding scale, data, and learning.
    
- How students are already using AI ‚Äî and what it means for teaching and research.
    
## Panorama Actual de la IA Generativa y LLMs: Una Mirada a sus Or√≠genes y a su Diferencial Evolutivo

La inteligencia artificial (IA) generativa y los modelos de lenguaje grandes (LLMs) est√°n marcando un punto de inflexi√≥n en la interacci√≥n entre humanos y tecnolog√≠a, con un potencial transformador en pr√°cticamente todos los sectores. Su panorama actual se caracteriza por una r√°pida evoluci√≥n y una adopci√≥n creciente, pero para comprender su alcance es fundamental analizar de d√≥nde venimos, qu√© los hace funcionar y por qu√© la ola actual es tan diferente.

### 1. Panorama Actual: Un Ecosistema en Plena Ebullici√≥n

El estado actual de la IA generativa y los LLMs se define por:

- **Capacidades Multimodales:**¬†Los modelos ya no se limitan al texto. Ahora pueden procesar y generar im√°genes, video, c√≥digo y m√∫sica, abriendo un vasto abanico de posibilidades.[[1](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQGyk3yyT74R49c6GZF-HyLDaDibTLK5d2SpHx-mb9YreNmq-kfnDKo4RHe819NlDaA6kUSzTH9zR8xvfsN7-0TUFrOOf1H6dsgRgMfIjH-CBpKC6QJCCwxZWIkWmKhhbEQ0wBi8z4V-8C5ikqqW5mV7nwFsEpWXgRKBkKNf-3Aku5TMK38W)]
    
- **Modelos de Gran Escala:**¬†El tama√±o y la complejidad de los modelos, con miles de millones de par√°metros, les permiten capturar y generar patrones complejos con una calidad sin precedentes.
    
- **Accesibilidad y Democratizaci√≥n:**¬†La proliferaci√≥n de modelos de c√≥digo abierto y plataformas accesibles est√° permitiendo a desarrolladores y empresas de todos los tama√±os experimentar e integrar estas tecnolog√≠as.[[2](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQHdSJfWkUEqILbr4F-NEtZzyPhv2NNupu5rKxRpJLRL81ajgjD_hcL0o0dg09JwoJ437KjuAIcSVyu2gZvjXXh8eYdmGy4kygb5LU1_HkgqPSp5uT8AUiHqi5bFVrLaJ388BDYSw80%3D)][[3](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQGYyJ8cZaT3QSXEuOgtdmziJcZHb0JfoZTuTi2FOkh5Eqzhg5Rw1dxvtcF6ud9Nlyy1JBdfVr75LEvE0_l9sPTJfLB_CCKxKgXkq28JHzpkSGkaXyAPipi2iRw4M_ItTLzhPdPrMU4%3D)]
    
- **Integraci√≥n Sectorial:**¬†Desde la automatizaci√≥n de tareas en el desarrollo de software y la atenci√≥n al cliente hasta la creaci√≥n de contenido personalizado en marketing y entretenimiento, la IA generativa se est√° integrando en flujos de trabajo de m√∫ltiples industrias.
    
- **Enfoque en la Eficiencia:**¬†Existe una tendencia hacia la creaci√≥n de modelos m√°s eficientes que requieran menos potencia de c√°lculo, haci√©ndolos m√°s sostenibles y accesibles.
    

### 2. ¬øDe D√≥nde Venimos? Un Camino de D√©cadas

La IA generativa no es un fen√≥meno reciente, sino la culminaci√≥n de d√©cadas de investigaci√≥n y desarrollo:

- **Fundamentos Te√≥ricos (A√±os 50):**¬†El Test de Turing propuesto por Alan Turing sent√≥ las bases conceptuales para evaluar la inteligencia de una m√°quina.
    
- **Primeros Modelos (A√±os 90):**¬†Los primeros modelos de lenguaje se basaban en m√©todos estad√≠sticos para predecir la siguiente palabra en una secuencia, con capacidades muy limitadas.[[1](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQGyk3yyT74R49c6GZF-HyLDaDibTLK5d2SpHx-mb9YreNmq-kfnDKo4RHe819NlDaA6kUSzTH9zR8xvfsN7-0TUFrOOf1H6dsgRgMfIjH-CBpKC6QJCCwxZWIkWmKhhbEQ0wBi8z4V-8C5ikqqW5mV7nwFsEpWXgRKBkKNf-3Aku5TMK38W)]
    
- **Redes Neuronales y Deep Learning (A partir de 2012):**¬†La reaparici√≥n del aprendizaje profundo o¬†deep learning¬†reactiv√≥ el campo, permitiendo a los modelos aprender de grandes cantidades de datos.
    
- **El Auge de los Modelos Pre-entrenados (A partir de 2018):**¬†Modelos como GPT (Generative Pre-trained Transformer) demostraron la viabilidad de pre-entrenar grandes modelos en vastos corpus de texto para luego adaptarlos a tareas espec√≠ficas.[[4](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQH2ACQTe2iOwtgZZ4xtJxFppuOBjDEySE5vW9hg_mp4_lBtwB_mGQSh3wU-zrsLxF42d_1fr6qovSMZHOXov_OxxdPPG_djqp15mx8-8e3JJganzlqXGMm9cnMWeFZzIoSRHIis1LFQCyrOLLKCsg6LqDhRPjC_f-e5ka8IfBLP-AQ%3D)]
    

### 3. El Punto de Inflexi√≥n: La Arquitectura Transformer y la Biblioteca Inteligente

La revoluci√≥n actual no habr√≠a sido posible sin un avance clave en 2017: la arquitectura¬†Transformer.[[5](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFDKD7NTX0Rnye0YwqXpetz4Bg-yBKXaJctW4YTfDOkPI6ZFRfBiF1lQSSkiWZelVIXX34c2fS7LygMi4tesgaHw9a9-n3rQ03mnmBtlR-3hiioIqQ2pgnZEKnKBq4yNRBbKjdg2MwmUPFnrfQH1-4-zraVpz41e8p_ux2G8TX2nY-aEKIyMOSXvyG-KdzrF0HN65RBhLobUd8C7JJmPzDGIwEO1Miaz5k%3D)]

- **¬øQu√© es un Transformer?:**¬†Es un tipo de arquitectura de red neuronal dise√±ada para procesar datos secuenciales, como el texto.[[6](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFF2drUNnSX_QHIriD6mR4SdbYSW6sAGPYDnOcTRVgJNcVyi8ikZlmGYCgixht4Lz3OaKN8VQCUeo6EGRyOaqztoN5hYaN-MAJcE0umZbGgrflWS89LiPASjrzd5GkPl4ORSnM%3D)][[7](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFGXapXjMgqlqGQpLnspMFYVmsq3GdtuJQVPPj46X7O_O48zkiUN_wiJhfKu6sr6i_wkFiIVW8o6i4YBN4NnKTNmY5n0kl6KEMnLKs9_RTwmmRfhuO3kyAvNYewwzsMTh2RsTuAP8956XD9H8iFCEnTUON0)] Su gran innovaci√≥n fue el "mecanismo de auto-atenci√≥n".[[8](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFWrTM9jnTgCpp4yHfxpxevtOXFRkZWNoiC1sKjkQmqSTNzxIScgPFFZCfTpNEGas7ok7qW5EnMnDJllTcHPzZeI5YxzZaEz9xoyuD5qaVlLtLqViHaeftRjZOYWtP195x-2-JmPU8WwvaNqaMcofO6RpZ_tuPmifK5VNHIznzb2wrFjefslMu4Cy7buaGq)] A diferencia de modelos anteriores que procesaban las palabras una por una en orden, la atenci√≥n permite al modelo analizar todas las palabras de una oraci√≥n a la vez y sopesar la importancia de cada una en relaci√≥n con las dem√°s para captar el contexto de forma mucho m√°s profunda y eficiente.[[9](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFMBPkx8kpkf36itbqxHdBvgJ9zl2hOiuwhqDWaTUbkluL73LByFtYkv_LLEhkBPbdneD8KEHvNvQjoQKVzxbFkQzcrA55F1iTaKwckoYzqJF1CS_iO9rzzNcp3drl2oBxjVHMIZtFpcwQRTCec5C7U)][[10](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFz19dENlnsiQ6QbldBZoe2bnYntnTJHDqmqMtRF0k85ejZP2wMGmVEg6UFl3I2iFjxBGxk_mzx8pB2UNANDEpejkTGHRs9x1nVepci3wPDa1q4nYJrzhXNfPXAQpoRWwWS_M6uyORi90yCTJrVNg8jwsdVINstags%3D)]
    
- **Analog√≠a: Dirigir una Biblioteca Inteligente:**
    
    - **La Petici√≥n (Input):**¬†Imagina que eres el director de una biblioteca y recibes una petici√≥n compleja: "Quiero un libro sobre la historia de los autos que no sea de una marca americana".
        
    - **El Antiguo Bibliotecario (Modelos RNN):**¬†El bibliotecario antiguo leer√≠a la petici√≥n palabra por palabra. Al llegar a "americana", podr√≠a haber olvidado el tema principal, "historia de los autos", y traerte un libro de historia de Am√©rica. Su memoria era secuencial y limitada.
        
    - **El Nuevo Director (Modelo Transformer):**¬†T√∫, como director con la arquitectura Transformer, lees la frase entera de un vistazo. Inmediatamente, tu "mecanismo de atenci√≥n" se activa.
        
        - **Ponderaci√≥n:**¬†Le das un gran peso a "historia de los autos" como el n√∫cleo de la petici√≥n.
            
        - **Relaciones:**¬†Conectas "marca" con "autos" y "americana" con "marca".
            
        - **Exclusi√≥n:**¬†Entiendes que "no sea" es una condici√≥n clave que modifica a "marca americana".
            
    - **El Resultado (Output):**¬†En lugar de procesar la petici√≥n de forma lineal, has creado un mapa de significados y relaciones entre todas las palabras simult√°neamente. Gracias a esto, vas directamente a la secci√≥n correcta y entregas un libro sobre la historia de Mercedes-Benz, cumpliendo con todos los matices de la petici√≥n. Esta capacidad de ver el "cuadro completo" y entender las relaciones a larga distancia en el texto es lo que hace al Transformer tan poderoso.
        

### 4. ¬øPor Qu√© es Diferente? La Clave de la Revoluci√≥n Actual

La actual era de la IA generativa se distingue de sus predecesoras por varias razones fundamentales:

- **Creaci√≥n de Contenido Original:**¬†A diferencia de la IA tradicional, que se enfoca en analizar y clasificar datos, la IA generativa es capaz de crear contenido completamente nuevo y original.
    
- **Calidad y Coherencia sin Precedentes:**¬†Gracias a los avances en la arquitectura de los modelos y al entrenamiento con cantidades masivas de datos, la calidad y coherencia del contenido generado es a menudo indistinguible del creado por humanos.
    
- **Capacidad de "Razonamiento" Emergente:**¬†Aunque no poseen una comprensi√≥n real, los LLMs actuales exhiben capacidades emergentes que se asemejan al razonamiento, la planificaci√≥n y la resoluci√≥n de problemas complejos.
    
- **Interacci√≥n Intuitiva:**¬†Las interfaces de lenguaje natural, como los chatbots, han hecho que esta tecnolog√≠a sea accesible para un p√∫blico no t√©cnico, permitiendo una interacci√≥n fluida y conversacional.
    
- **Impacto Disruptivo y Escalable:**¬†La capacidad de automatizar tareas cognitivas y creativas a gran escala est√° generando una transformaci√≥n profunda en la productividad y la naturaleza del trabajo en m√∫ltiples sectores.
**Hands-on:**

- Compare outputs from ChatGPT Edu, Claude, and Gemini using the same academic prompt.
    
- Discuss differences in reasoning, bias, and tone.
    
### El "Pensamiento" como Predicci√≥n de Patrones

En su n√∫cleo, un LLM es un motor de predicci√≥n de patrones incre√≠blemente avanzado.[[1](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFOrj5VbrX-T54qUtHG3IZTnbBu0zGBb0ivdabBy0fOXVYd8A6xcBIvkOlWwzXDhIAd-IA_NgWOJ7YCCxXEYR0PJuuKLBj7sesPNTkm3IjnyQvtkzJk1oM0KTUO-GJLDcahGLKuNQiBce0n0woe_iLbV2_ZHkzfkMwxWsRnCOep0AHWc2YodMxP)][[2](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFviMK_sGyFgVI-4s5TcNk-pVJevcrHa0cDqXOibWmVYVeVQiyVQ8bVEiSO-eW5W2-WCR0kpR9oJyDPjv-sftl253SwrqbiS-ySNVebXtYbh6IfmOwF-2E5zLV-RI1iDwOOrQUqr_CjBGuvD_KW6Gh8)] Su √∫nica funci√≥n fundamental es predecir la siguiente palabra (o "token") m√°s probable en una secuencia, bas√°ndose en los miles de millones de ejemplos de texto con los que fue entrenado.[[1](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFOrj5VbrX-T54qUtHG3IZTnbBu0zGBb0ivdabBy0fOXVYd8A6xcBIvkOlWwzXDhIAd-IA_NgWOJ7YCCxXEYR0PJuuKLBj7sesPNTkm3IjnyQvtkzJk1oM0KTUO-GJLDcahGLKuNQiBce0n0woe_iLbV2_ZHkzfkMwxWsRnCOep0AHWc2YodMxP)][[2](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFviMK_sGyFgVI-4s5TcNk-pVJevcrHa0cDqXOibWmVYVeVQiyVQ8bVEiSO-eW5W2-WCR0kpR9oJyDPjv-sftl253SwrqbiS-ySNVebXtYbh6IfmOwF-2E5zLV-RI1iDwOOrQUqr_CjBGuvD_KW6Gh8)]

Lo que percibimos como "pensamiento" o "razonamiento" es el resultado de esta predicci√≥n de secuencias llevada a un nivel de complejidad extremo. El modelo no "sabe" que est√° resolviendo un problema; simplemente est√° generando la secuencia de palabras que estad√≠sticamente sigue a una pregunta que requiere una soluci√≥n.

### 1. Razonamiento Emergente: Cuando el Todo es Mayor que la Suma de sus Partes

El razonamiento es una de las capacidades m√°s sorprendentes que "emergen" de los LLMs. La emergencia es un fen√≥meno donde un sistema exhibe comportamientos complejos que no est√°n presentes en sus componentes individuales, pero que surgen de sus interacciones a gran escala.[[3](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQEWHIqynEqsDX43LupyKaM7E_lFhuSB46wB78DCH_wB7RMdMhaJXluOv0NyCUeLJdCTr9hBGRdHc32x0iBBe2vckHkBnEbKhJvr9eMcLkpT1vp8Tw3Qeb8y2dXRozxqgCbKZDEZ5cW8rhU627Yjv4TM9pbUajIEH4-2jgi2dTzPpQeI8c1NTH3ugeFbpdTMOWLFgWHfX0Gn9kE%3D)]

- **Analog√≠a - El Hervir del Agua:**¬†Las mol√©culas de agua individuales no "hierven". Sin embargo, cuando se calientan juntas a 100¬∞C, emerge el comportamiento colectivo de la ebullici√≥n.[[3](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQEWHIqynEqsDX43LupyKaM7E_lFhuSB46wB78DCH_wB7RMdMhaJXluOv0NyCUeLJdCTr9hBGRdHc32x0iBBe2vckHkBnEbKhJvr9eMcLkpT1vp8Tw3Qeb8y2dXRozxqgCbKZDEZ5cW8rhU627Yjv4TM9pbUajIEH4-2jgi2dTzPpQeI8c1NTH3ugeFbpdTMOWLFgWHfX0Gn9kE%3D)]
    
- **En los LLMs:**¬†Las habilidades como el razonamiento l√≥gico, la traducci√≥n entre idiomas en los que no fue entrenado o la depuraci√≥n de c√≥digo, no fueron programadas.[[3](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQEWHIqynEqsDX43LupyKaM7E_lFhuSB46wB78DCH_wB7RMdMhaJXluOv0NyCUeLJdCTr9hBGRdHc32x0iBBe2vckHkBnEbKhJvr9eMcLkpT1vp8Tw3Qeb8y2dXRozxqgCbKZDEZ5cW8rhU627Yjv4TM9pbUajIEH4-2jgi2dTzPpQeI8c1NTH3ugeFbpdTMOWLFgWHfX0Gn9kE%3D)] Aparecen espont√°neamente una vez que el modelo alcanza un tama√±o y una cantidad de datos de entrenamiento cr√≠ticos.[[3](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQEWHIqynEqsDX43LupyKaM7E_lFhuSB46wB78DCH_wB7RMdMhaJXluOv0NyCUeLJdCTr9hBGRdHc32x0iBBe2vckHkBnEbKhJvr9eMcLkpT1vp8Tw3Qeb8y2dXRozxqgCbKZDEZ5cW8rhU627Yjv4TM9pbUajIEH4-2jgi2dTzPpQeI8c1NTH3ugeFbpdTMOWLFgWHfX0Gn9kE%3D)][[4](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQEuthTphZsfo54_YRZSyiwLx9X5fWHjhQ1cUjk2vF_HgfNmlSnOxXp9_e7es6bUcBiW8ZsKsI-LkbLprGNDTJrYF1Mbq002QcDfFNz-8U6Of4kwdnNWs2iuXTQPYXvgXCry7TZ28QDAwPfm7QALzbXswfBX8yyE5Z1tu6w6wFk324Tfw7D8)]
    

**¬øC√≥mo aprende a razonar?**¬†Al procesar un volumen masivo de lenguaje humano, el LLM aprende impl√≠citamente las estructuras l√≥gicas incrustadas en el texto.[[3](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQEWHIqynEqsDX43LupyKaM7E_lFhuSB46wB78DCH_wB7RMdMhaJXluOv0NyCUeLJdCTr9hBGRdHc32x0iBBe2vckHkBnEbKhJvr9eMcLkpT1vp8Tw3Qeb8y2dXRozxqgCbKZDEZ5cW8rhU627Yjv4TM9pbUajIEH4-2jgi2dTzPpQeI8c1NTH3ugeFbpdTMOWLFgWHfX0Gn9kE%3D)] Palabras y frases como "si... entonces", "porque", "por lo tanto" y "en consecuencia" codifican relaciones de causa y efecto. El modelo aprende a replicar estos patrones l√≥gicos para generar texto coherente que imita el pensamiento estructurado.[[3](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQEWHIqynEqsDX43LupyKaM7E_lFhuSB46wB78DCH_wB7RMdMhaJXluOv0NyCUeLJdCTr9hBGRdHc32x0iBBe2vckHkBnEbKhJvr9eMcLkpT1vp8Tw3Qeb8y2dXRozxqgCbKZDEZ5cW8rhU627Yjv4TM9pbUajIEH4-2jgi2dTzPpQeI8c1NTH3ugeFbpdTMOWLFgWHfX0Gn9kE%3D)]

### 2. Planificaci√≥n y Resoluci√≥n de Problemas: El Poder del "Mon√≥logo Interno"

Los LLMs abordan problemas complejos no con un entendimiento profundo, sino descomponi√©ndolos en pasos secuenciales. Esto se logra a trav√©s de t√©cnicas que fuerzan al modelo a "pensar en voz alta".

#### **Cadena de Pensamiento (Chain-of-Thought - CoT)**

Esta es la t√©cnica m√°s fundamental. En lugar de pedir una respuesta directa, se le indica al modelo que razone paso a paso.[[5](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQGX2iXpF_gFmYVg94luELqgE4bzLCIQdvypyPEROGfKVpvqDfyU1fUsj_tqd_rXBSkt209kJb1pKEU1BK_j_3Mx4FvJyt_AsAuI-NelUkeaK4TtseJWRbag2xj3qTmd43qEsZEZ6_o%3D)][[6](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQHRHEO6LE-uDew47SXJ6jZnTMjcS0r5vQIyF9vjwjE0Z7pHid6qj3BCEBw1mc8_1ysf-XDnfJZ7G6P0GEl1cAhdoeh-YqGAHIsGwil8mPvW_uvXkHkNmu6qGX81CHiuE1x22BcMHKWcEgDwXyU%3D)][[7](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQF0C_jjyAd-F2ZyiS9LWLmK1bDl_4jHpTH1cT_EUV4QHJDfqhYRvdvD8z4qH7m4IgN0I2l70Z6XUn6Ds76bNGOaQm7LUPwlRy7odWms9NZILTdlLTRPHYspmDmUA6tFsmHZu2A9Wt9GIpuEALTlhjOzEzvZjTBe8H4%3D)]

- **Sin CoT:**¬†"Tengo 10 manzanas, doy 2 y compro 5 m√°s. ¬øCu√°ntas tengo?" -> El modelo podr√≠a responder "13" directamente y equivocarse.
    
- **Con CoT (usando el simple a√±adido "Pensemos paso a paso"):**¬†"Pensemos paso a paso. Empec√© con 10 manzanas. Regal√© 2, as√≠ que me quedaron 10 - 2 = 8. Luego compr√© 5 m√°s, as√≠ que ahora tengo 8 + 5 = 13. La respuesta final es 13".
    

Al forzar esta secuencia, el modelo sigue un camino l√≥gico m√°s fiable, reduciendo errores.[[6](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQHRHEO6LE-uDew47SXJ6jZnTMjcS0r5vQIyF9vjwjE0Z7pHid6qj3BCEBw1mc8_1ysf-XDnfJZ7G6P0GEl1cAhdoeh-YqGAHIsGwil8mPvW_uvXkHkNmu6qGX81CHiuE1x22BcMHKWcEgDwXyU%3D)][[8](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQGrxlhGFHDZAAX6lGxAHqKyEC3jZzCvapiU-jJVksjClYD-uC5DG0aFza9YfcovOGFr3eFn3MAAt1hQZm2JoHKuFq6v_Pwz4AFL6vSxnwD353caDXZ6dGuj9XWjkc6fwLcTstQ2QrTtUDF11dsA3wvB77pTjYb1lw%3D%3D)][[9](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFJw-g_j38dj8iAoc6U1KLRDi8XtLEy1dpDR8H9jEjF5AgyYwgvqPkiW8DAZRkrbpfQDr-_xHynLHA8UpnYp4ImIV9CWn5P-pxCc8UQvzDy2MShyTCJqSBGs_seuK_feHvqrbgBcmL_ygBS3-z67g%3D%3D)] Simula un proceso de razonamiento humano al desglosar el problema.[[6](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQHRHEO6LE-uDew47SXJ6jZnTMjcS0r5vQIyF9vjwjE0Z7pHid6qj3BCEBw1mc8_1ysf-XDnfJZ7G6P0GEl1cAhdoeh-YqGAHIsGwil8mPvW_uvXkHkNmu6qGX81CHiuE1x22BcMHKWcEgDwXyU%3D)]

#### **Mon√≥logo Interno (Inner Monologue)**

Este es un concepto m√°s avanzado donde el modelo genera un di√°logo interno para procesar informaci√≥n, evaluar el entorno y corregir su plan sobre la marcha.[[10](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQHWfBdHkMjxqT4FzUVmmkT5Bots01Fje2JuSL_ENdrKQMA7Km6mCSQZiJIN-wJeMwz7Lo86Zlle7u0YM3KZSt4dHbgmF6gSry5AskjiC__6j4rYPXzai8YVK7izCqD4MzeDebQiRVFRaGf60pewBWLwz_s%3D)][[11](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQEbaH2LxRh0TEv0IPjTZEbUEKDeioIRkB0orKLMjRerGuOinkakAoccDSO9JZLiHYzt9Ub5fFY4n7DE2iKQ2YEGvPCYnlRDqYtKQWHgqHmvDQ9Mhwf_yH735RlH-RrVRm4yDR_O0W3cbzhjo8Vnori2RrBYeVuFWQCub0Z7TMss-nZ3UZyoDj7EWSj6E-Z-i_oT6-amTioM1MOiGkqKOc8%3D)][[12](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQEB0a2hE1O36DGYJF0xp-vS-CNvCmkf0ckflD8siXuSQ267_tU7o6N0Wu7WbgYvuJXn11CA685kVPzoNFCQWxpOgRPs5khhATybQoQJUuRrib1Rt8Nqjgu2jEZ56rb8YrNUoktx6g%3D%3D)] Se utiliza a menudo en rob√≥tica y tareas interactivas.[[10](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQHWfBdHkMjxqT4FzUVmmkT5Bots01Fje2JuSL_ENdrKQMA7Km6mCSQZiJIN-wJeMwz7Lo86Zlle7u0YM3KZSt4dHbgmF6gSry5AskjiC__6j4rYPXzai8YVK7izCqD4MzeDebQiRVFRaGf60pewBWLwz_s%3D)][[13](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQEi1iPTySMJLJ7DH6Fxz_OjkRwFcIvLIDtwk10p2gvAeLbYYvaPMHvgKBxmzcwvqF0MRyIP12mEQuQie0zaRerucdDbP0of97woJ-VK83hqT1-uzfrs_7owdCc%3D)]

- **Ejemplo de un robot:**
    
    1. **Objetivo:**¬†"Recoge la botella de agua".
        
    2. **Plan Inicial (Mon√≥logo):**¬†"Ok, primero necesito localizar la botella. Luego, mover mi brazo hacia ella. Despu√©s, cerrar la pinza".
        
    3. **Retroalimentaci√≥n del Entorno:**¬†El robot intenta agarrar la botella pero falla.
        
    4. **Correcci√≥n del Plan (Mon√≥logo):**¬†"El agarre fall√≥. La botella est√° resbaladiza. Intentar√© de nuevo, pero aplicando m√°s presi√≥n en la pinza".[[14](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFDceaVx2uqfImJ24k-fxqJD4m6MDb1XvIrHVNJjKBV9tKo6MFOXcAwKwxt7Zcuebv5J-EBDmcIMjuAMuhE8DPd_6LkAHw6EOSoR5JVNtGMMly_XviReAtkn6iw)]
        

Este bucle de planificar, actuar, recibir retroalimentaci√≥n y replanificar es crucial para resolver problemas complejos en entornos din√°micos.[[13](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQEi1iPTySMJLJ7DH6Fxz_OjkRwFcIvLIDtwk10p2gvAeLbYYvaPMHvgKBxmzcwvqF0MRyIP12mEQuQie0zaRerucdDbP0of97woJ-VK83hqT1-uzfrs_7owdCc%3D)]

### 3. Resoluci√≥n de Problemas de Alta Complejidad

Para desaf√≠os que superan el razonamiento secuencial simple, se emplean m√©todos m√°s sofisticados:

- **Jerarqu√≠a de Razonamiento:**¬†Investigaciones recientes muestran que los modelos aprenden a resolver problemas de forma jer√°rquica, similar a los humanos. Primero dominan las tareas de bajo nivel (como la aritm√©tica simple o el formato correcto) y luego se enfocan en la estrategia de alto nivel (el plan general para resolver el problema).[[15](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQGVkhu9ssb1dkuh86Ui1aqDLFAcq2zFE6Wr0M2pdeGVVV77tFHvSYPiLjetXQ-smw67TbnFVtPi_pwNphe-a3kBNnFYtXnyr-W2GcUYA_0qXnIBjmglKp56gFuASGHfZ7bFL9lJfhI2rHO7K6N71D8%3D)][[16](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFEjmxuhbH86Ry6knpBGZ4lB7nYIciOCRw7ECmxRj1FiS3zh_W8HU0n7553QaCJ47BaUuyVz-SWAgIGNoktdPWBFTfPTmNOkNJFsAoD-XAJ-ZYC0KEWizgQBWY%3D)]
    
- **Integraci√≥n con Herramientas Externas:**¬†Para problemas de optimizaci√≥n muy complejos (ej. log√≠stica de una cadena de suministro), el LLM puede actuar como un "traductor".[[17](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFpPneQXwRjYxQTHLyP1owjnYgo8J5UET5UaECgw-EedjNvfw2DCK3rSrnLf8LnNhz6xx3POm1OYRYtgh_Mbb1C2DBeZa8s4kgtWa2JU9VpF4meQBB0lZawIUgtsKrDxV9xhFPs4r_7yoXAJy3MhDAgaV5qLltpdS6AhrTMKzzO2IUd-1JvWMy5NoCI7kzQ6rHBMc7b)][[18](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFDzrugwilgAkJ2HDGIFo-oryUcwYBK5Jxt9iUhP5fVxS6wObhtiLrR3giNV1pJxg-WE1dnR8SLMvN2Ylk8anQ3EsIYw03wmGNZ03ifNd3zil6rDfe0q5xLeMDn6gY%3D)] Convierte la descripci√≥n del problema en lenguaje natural a un formato estructurado que un software de optimizaci√≥n cl√°sico (un "solver") puede entender.[[17](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFpPneQXwRjYxQTHLyP1owjnYgo8J5UET5UaECgw-EedjNvfw2DCK3rSrnLf8LnNhz6xx3POm1OYRYtgh_Mbb1C2DBeZa8s4kgtWa2JU9VpF4meQBB0lZawIUgtsKrDxV9xhFPs4r_7yoXAJy3MhDAgaV5qLltpdS6AhrTMKzzO2IUd-1JvWMy5NoCI7kzQ6rHBMc7b)][[18](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFDzrugwilgAkJ2HDGIFo-oryUcwYBK5Jxt9iUhP5fVxS6wObhtiLrR3giNV1pJxg-WE1dnR8SLMvN2Ylk8anQ3EsIYw03wmGNZ03ifNd3zil6rDfe0q5xLeMDn6gY%3D)] Luego, traduce la soluci√≥n del solver de vuelta a un lenguaje comprensible para el usuario.[[17](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFpPneQXwRjYxQTHLyP1owjnYgo8J5UET5UaECgw-EedjNvfw2DCK3rSrnLf8LnNhz6xx3POm1OYRYtgh_Mbb1C2DBeZa8s4kgtWa2JU9VpF4meQBB0lZawIUgtsKrDxV9xhFPs4r_7yoXAJy3MhDAgaV5qLltpdS6AhrTMKzzO2IUd-1JvWMy5NoCI7kzQ6rHBMc7b)]
    

En resumen, el "pensamiento" de un LLM no es un proceso de cognici√≥n interna, sino una¬†**simulaci√≥n de razonamiento a trav√©s de la generaci√≥n de texto secuencial y estructurado**. Las habilidades emergentes surgen de la escala, y las t√©cnicas como la "Cadena de Pensamiento" y el "Mon√≥logo Interno" gu√≠an su proceso probabil√≠stico por un camino que se asemeja a la l√≥gica y la planificaci√≥n humanas.
---

### **Session 2 ‚Äî Tools and Foundations (1.5 hrs)**

**Goal:** Equip participants with essential tools for applied AI use.  
**Content:**

- Overview of the AI ecosystem: LLMs, open-source models, cloud systems.
    
- CrewAI and other orchestration tools: from single models to multi-agent collaboration.
    
- Building and using a small ‚Äúknowledge base‚Äù or custom dataset.
    

**Hands-on:**

- Build a small AI workspace using one of the educational tools.
    
- Upload a short corpus (e.g., 10 PDFs or articles) and query it using an AI assistant.
    

---

### **Session 3 ‚Äî Prompting as Computation (3 hrs)**

**Goal:** Learn to communicate effectively with AI systems.  
**Content:**

- Prompt engineering principles (structure, context, intent, and iteration).
    
- Text as code ‚Äî thinking computationally.
    
- ‚ÄúComputational creativity‚Äù: how syntax and framing change AI reasoning.
    
- Common failure modes and debugging prompts.
    

**Hands-on (2 hrs):**

- Participants design a prompt sequence that performs an academic or creative task (literature summary, policy memo, lesson plan, short essay, simulation, etc.).
    
- Introduce the idea of prompt versioning (each iteration improves clarity).
    
- Optional: short creative exercise (‚ÄúComputational Poetry‚Äù) to practice lateral thinking.
    

---

## **DAY 2 ‚Äî Building, Collaborating, and Reflecting with AI (6 hours)**

### **Session 4 ‚Äî Ethics, Bias, and Responsible Use (1.5 hrs)**

**Goal:** Understand the ethical, social, and cognitive implications of AI systems.  
**Content:**

- Bias, data provenance, and transparency.
    
- AI as collaborator: where responsibility remains human.
    
- The politics of access and the future of open-source AI.
    
- Privacy and academic integrity in AI-assisted environments.
    

**Hands-on (45 min):**

- Analyze an AI-generated policy or research text and identify ethical risks.
    
- Design a short ‚ÄúResponsible AI Use Statement‚Äù for your class or institution.
    

---

### **Session 5 ‚Äî Advanced Applications and Use Cases (2 hrs)**

**Goal:** Connect AI theory to real, domain-specific applications.  
**Content:**  
Explore six short examples:

1. Public governance (upu, GovTech, etc.)
    
2. Academic writing and peer review
    
3. Data analysis and visualization
    
4. Creative writing or design
    
5. Cloud-based multi-agent systems
    
6. Local open-source implementations
    

**Hands-on (1.5 hrs):**

- Participants select one case and reimagine it in their own discipline (education, health, governance, science, etc.).
    
- They design a ‚Äúworkflow‚Äù diagram showing where AI adds value.
    

---

### **Session 6 ‚Äî Collaborative Projects and Future Thinking (2.5 hrs)**

**Goal:** Apply everything learned to create a functional or conceptual AI project.  
**Content:**

- Team formation by shared interest.
    
- Definition of a question, challenge, or opportunity.
    
- Designing an AI-driven workflow or prototype.
    

**Hands-on (2 hrs):**

- Teams co-create an AI solution, using any tool or method learned (prompt chain, AI tutor, assistant, content generator, analyzer, etc.).
    
- Prepare a short presentation (5 min) including:
    
    - What the AI did
        
    - What the human did
        
    - What was learned
        

**Reflection (30 min):**

- Group discussion: What surprised you?
    
- How should AI literacy evolve in academia?
    
- Personal commitments for ethical and effective use.
    

---

## üß© **Evaluation / Closing**

- No grades ‚Äî but participants share a **Project Canvas** with:
    
    - Problem statement
        
    - Workflow diagram
        
    - AI tools used
        
    - Ethical reflection
        

---

## **Time & Practice Distribution**

|Block|Theme|Time|Mode|Focus|
|---|---|---|---|---|
|1|The AI Landscape|1.5 hrs|Conceptual + Practical|50/50|
|2|Tools & Foundations|1.5 hrs|Hands-on|30/70|
|3|Prompting as Computation|3 hrs|Hands-on|25/75|
|4|Ethics & Responsibility|1.5 hrs|Applied Reflection|50/50|
|5|Advanced Applications|2 hrs|Applied Practice|25/75|
|6|Collaborative Projects|2.5 hrs|Co-creation|10/90|
|**Total**||**12 hrs**||**~30% Theory / 70% Practice**|

---

## üß† **Pedagogical Design Principles (implicit HA influence)**

Without naming HA, the course integrates:

- **Systemic thinking:** every tool or case connects across disciplines.
    
- **Multi-perspective collaboration:** humans + AI + peers as a single cognitive system.
    
- **Temporal reasoning:** from immediate utility to long-term institutional change.
    
- **Reflective intelligence:** combining computation and ethics.