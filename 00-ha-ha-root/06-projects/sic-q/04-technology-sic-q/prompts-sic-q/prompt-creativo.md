# **C.R.E.A.T.I.V.O.**
[[04-technology-sic-q]]


---

- **C - Contexto (Context):**
    
    ### `¬øCu√°l es el trasfondo o la situaci√≥n?`
    

---

- **R - Rol (Role):**
    
    ### `¬øQui√©n quieres que sea la IA?`
    

---

- **E - Ejemplo (Example):**
    
    ### `¬øPuedes mostrarle un ejemplo de lo que quieres?`
    

---

- **A - Audiencia (Audience):**
    
    ### `¬øPara qui√©n es la respuesta?`
    

---

- **T - Tarea (Task):**
    
    ## `¬øCu√°l es la acci√≥n espec√≠fica que debe realizar?`
    

---

- **I - Instrucciones (Constraints & Format):**
    
    ## `¬øCu√°les son las reglas y el formato de salida?`
    
    - **`Restricciones:** Lo que NO debe hacer.`
    - **`Formato de Retorno:** C√≥mo debe verse la respuesta.`

---

- **V - Voz y Tono (Voice & Tone):**
    
    ### `¬øC√≥mo debe sonar la respuesta?`
    

---

- **O - Objetivo (Goal):**
    
    ### `¬øCu√°l es el prop√≥sito final o el porqu√© de la tarea?`
    

---
# **C - Contexto (Context) ‚Üí "Contextual Priming" o "Background Framing‚Äù**

<aside>
üí°

**Qu√© es:** 

*Darle el trasfondo de tu petici√≥n. Es el "`porqu√©`" detr√°s de tu pregunta.*

- **Explicaci√≥n t√©cnica:**
    
    
    El contexto **activa selectivamente las representaciones latentes en el espacio de embeddings del modelo**, reduciendo la entrop√≠a de las distribuciones de probabilidad posteriores. Funciona como un mecanismo de atenci√≥n que sesga la generaci√≥n hacia dominios sem√°nticos espec√≠ficos.
    
- **Analog√≠a de la biblioteca:**
    
    
    *No solo pides un libro, sino que le dices al bibliotecario:* 
    
    ### `"Estoy preparando una presentaci√≥n para mi jefa sobre estrategias de marketing digital."`
    
    <aside>
    
    Inmediatamente, la persona bibliotecaria descarta el 99% de los libros de "negocios" (contabilidad, log√≠stica, etc.) y se enfoca en lo que necesitas.
    
    </aside>
    
- **Ejemplo:**
    
    > CONTEXTO: 
    `Estoy escribiendo un paper para Nature Computational Science sobre la aplicaci√≥n de teor√≠a de redes complejas para optimizar arquitecturas de transformers. Los revisores del primer round pidieron clarificar la conexi√≥n entre small-world networks y attention mechanisms. Necesito reformular el abstract para enfatizar esta relaci√≥n sin exceder 150 palabras.`
    > 
    > 
    > `PREGUNTA: ¬øC√≥mo puedo reescribir mi abstract?`
    > 
- **Referencias:**
    
    > `Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2023). "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing." *ACM Computing Surveys*, 55(9), 1-35.`
    > 
</aside>

# **R - Rol (Role) ‚Üí "Role-Based Prompting" o "Persona-Driven Instruction‚Äù**

<aside>
üí°

**Qu√© es:** 

*Decirle a la IA qu√© "sombrero" o profesi√≥n debe adoptar. Esto activa el conocimiento y los patrones de lenguaje asociados con ese rol.*

- **Explicaci√≥n t√©cnica:**
    
    
    La asignaci√≥n de roles explota la naturaleza composicional de los *transformers*, **activando subredes espec√≠ficas entrenadas en corpus especializados**. Esto induce un comportamiento consistente con el conocimiento y estilo ling√º√≠stico del rol especificado.
    
- **Analog√≠a de la biblioteca:**
    
    *Le dices al bibliotecario:* 
    
    ### `"Act√∫a como un asesor experto en startups de tecnolog√≠a."`
    
    <aside>
    
    Ahora no solo buscar√° libros, sino que te los recomendar√° desde la perspectiva de alguien que entiende el ecosistema tecnol√≥gico, d√°ndote consejos que un bibliotecario generalista no podr√≠a.
    
    </aside>
    
- **Ejemplo:**
    
    > `Act√∫a como un hybrid entre Geoffrey Hinton (deep learning pioneer) y Albert-L√°szl√≥ Barab√°si (network scientist). Tienes d√©cadas de experiencia publicando en journals Q1 y eres editor asociado de Science Advances. Tu especialidad es identificar conexiones no obvias entre campos aparentemente distantes. Eval√∫a esta hip√≥tesis: "Los LLMs exhiben propiedades de criticalidad auto-organizada similar a los sistemas complejos biol√≥gicos durante el fine-tuning."`
    > 
- **Referencias:**
    
    > `Bai, Y., Kadavath, S., Kundu, S., et al. (2022). "Constitutional AI: Harmlessness from AI feedback." *arXiv preprint arXiv:2212.08073*.`
    > 

---

</aside>

# **E - Ejemplo (Example) ‚Üí "Few-Shot Learning" o "In-Context Learning (ICL)‚Äù**

<aside>
üí°

**Qu√© es:** 

*Mostrarle a la IA exactamente c√≥mo se ve un buen resultado. Es una forma eficiente de alinear su "creatividad" con tu necesidad.*

- **Explicaci√≥n t√©cnica:**
    
    
    **Los ejemplos funcionan como** **vectores de demostraci√≥n que establecen un mapeo impl√≠cito entre entradas y salidas** sin actualizar los pesos del modelo. El mecanismo de atenci√≥n identifica patrones estructurales y los replica mediante inferencia bayesiana aproximada.
    
- **Analog√≠a de la biblioteca:**
    
    
    *Le ense√±as un p√°rrafo de un art√≠culo que te gust√≥ y le dices:* 
    
    ### `"**Busco libros que expliquen las cosas con este nivel de detalle y claridad.**"`
    
    <aside>
    
    El bibliotecario ahora entiende perfectamente el estilo que buscas y puede encontrar coincidencias exactas.
    
    </aside>
    
- **Ejemplo:**
    
    > `Necesito generar t√≠tulos para papers siguiendo este patr√≥n:`
    > 
    > 
    > `Ejemplo 1: "Emergent Hierarchical Structures in Multi-Agent Reinforcement Learning: A Complex Systems Perspective"`
    > 
    > `Ejemplo 2: "Phase Transitions in Neural Architecture Search: Evidence from 10,000 Experiments"`
    > 
    > `Ejemplo 3: "The Topology of Artificial Reasoning: Mapping Logical Structures in Large Language Models"`
    > 
    > `Ahora genera un t√≠tulo para mi paper sobre aplicaci√≥n de percolation theory a la robustez de modelos de visi√≥n computacional.`
    > 
    
- **Referencias:**
    
    > `Brown, T., Mann, B., Ryder, N., et al. (2020). "Language models are few-shot learners." *NeurIPS*, 33, 1877-1901. 
    
    Xie, S. M., Raghunathan, A., Liang, P., & Ma, T. (2022). "An explanation of in-context learning as implicit Bayesian inference." *ICLR 2022*.
    
    Min, S., Lyu, X., Holtzman, A., et al. (2022). "Rethinking the role of demonstrations: What makes in-context learning work?" *EMNLP 2022*.`
    > 
</aside>

# **A - Audiencia (Audience) ‚Üí "Audience Adaptation" o "Register Specification‚Äù**

<aside>
üí°

**Qu√© es:** 

*Especificar para qui√©n es la respuesta. Esto ajusta la complejidad, el vocabulario y el enfoque del resultado.*

- **Explicaci√≥n t√©cnica:**
    
    
    **Controla el registro ling√º√≠stico** mediante la modulaci√≥n de distribuciones l√©xicas y sint√°cticas. **Ajusta m√©tricas de complejidad** (Flesch-Kincaid, SMOG) **y selecci√≥n terminol√≥gica** bas√°ndose en modelos de audiencia objetivo.
    
- **Analog√≠a de la biblioteca:**
    
    
    *Le dices:* 
    
    ### `"**El libro es para un grupo de becarios que no saben nada de marketing.**"`
    
    <aside>
    
    El bibliotecario evitar√° los textos acad√©micos densos y buscar√° libros introductorios, claros y con muchos ejemplos pr√°cticos.
    
    </aside>
    
- **Ejemplo**
    
    > `Explica el concepto de "emergence in neural scaling laws" para TRES audiencias:`
    > 
    > 1. `Para revisores de Physical Review Letters (f√≠sicos te√≥ricos)`
    > 2. `Para el board de inversores de mi startup (ejecutivos no-t√©cnicos)`
    > 3. `Para estudiantes de doctorado en mi seminario de sistemas complejos`
    > 
    > `Ajusta vocabulario, ejemplos y profundidad matem√°tica para cada audiencia.`
    > 
- **Referencias**
    
    > `Kang, H., & Hovy, D. (2021). "Style is NOT a single variable: Case studies for cross-stylistic language understanding." *ACL-IJCNLP*, 2353-2365.
    
    Reiter, E., & Dale, R. (2000). *Building Natural Language Generation Systems*. Cambridge University Press.`
    > 
</aside>

# **T - Tarea (Task) ‚Üí "Task Decomposition" o "Instruction Tuning‚Äù**

<aside>
üí°

**Qu√© es:** 

***El verbo de acci√≥n.** La instrucci√≥n espec√≠fica e inequ√≠voca de lo que quieres que haga.*

- **Explicaci√≥n t√©cnica:**
    
    **Define operadores sem√°nticos espec√≠ficos que gu√≠an la funci√≥n objetivo del modelo**. La descomposici√≥n expl√≠cita de tareas reduce la ambig√ºedad y mejora la alineaci√≥n entre intenci√≥n y ejecuci√≥n.
    
- **Analog√≠a de la biblioteca:**
    
    
    *En lugar de `"necesito informaci√≥n"`, dices*: 
    
    ### `"**Crea una lista con vi√±etas de los 5 libros m√°s influyentes sobre marketing de contenidos publicados en los √∫ltimos 2 a√±os.**"`
    
    <aside>
    
    La tarea es clara, espec√≠fica y medible.
    
    </aside>
    
- **Ejemplo:**
    
    > `Desarrolla una arquitectura de prompts recursivos para analizar papers.`
    > 
    > 
    > `Descomp√≥n en estas sub-tareas:`
    > 
    > 1. `EXTRAER: Identificar claim principal, metodolog√≠a y conclusiones`
    > 2. `EVALUAR: Assess validez estad√≠stica y reproducibilidad`
    > 3. `CONECTAR: Mapear citas y construir grafo de conocimiento`
    > 4. `SINTETIZAR: Generar meta-an√°lisis estructurado`
    > 5. `PROPONER: Sugerir 3 extensiones experimentales`
    > 
    > `Ejecuta este pipeline con el paper: [DOI: 10.1038/s41586-023-06647-8]`
    > 
- **Referencias:**
    
    > `Ouyang, L., Wu, J., Jiang, X., et al. (2022). "Training language models to follow instructions with human feedback." *NeurIPS*, 35, 27730-27744.
    
    Wei, J., Wang, X., Schuurmans, D., et al. (2022). "Chain-of-thought prompting elicits reasoning in large language models." *NeurIPS*, 35, 24824-24837.
    
    Khot, T., Trivedi, H., Finlayson, M., et al. (2023). "Decomposed prompting: A modular approach for solving complex tasks." *ICLR 2023*.`
    > 
</aside>

# **I - Instrucciones (Constraints & Format)**

<aside>
üí°

**Qu√© es:** 

***Las reglas del juego.** L√≠mites, cosas que debe evitar y, crucialmente, c√≥mo debe estructurar la respuesta.*

- **Explicaci√≥n t√©cnica**
    
    
    Implementa **restricciones duras y blandas mediante *tokens* de control y templates estructurados**. Utiliza programaci√≥n l√≥gica para garantizar conformidad con especificaciones formales.
    
- **Analog√≠a de la biblioteca:**
    
    
    *Le dices:* 
    
    ### `"**La lista no debe incluir libros de m√°s de 300 p√°ginas (Restricci√≥n). Por favor, entr√©game la lista en una ficha, con el t√≠tulo en negrita, el autor debajo y un resumen de una sola frase (Formato).**"`
    
    <aside>
    
    Ahora no solo obtienes la informaci√≥n correcta, sino que la obtienes exactamente como la necesitas.
    
    </aside>
    
- **Ejemplo:**
    
    > `Genera un research proposal con estas restricciones:`
    > 
    > 
    > `RESTRICCIONES DURAS:`
    > 
    > - `M√°ximo 2 p√°ginas (1000 palabras)`
    > - `Debe incluir ecuaciones en LaTeX`
    > - `Presupuesto < $150,000 USD`
    > - `Timeline: 12 meses`
    > - `Citar m√≠nimo 5 papers de 2024`
    > 
    > `FORMATO OBLIGATORIO:`
    > 
    > ```markdown
    > # T√≠tulo (max 15 palabras)
    > ## PI: [Nombre] | Co-PI: [Nombre]
    > 
    > ### Abstract (100 palabras)
    > ### Hypothesis & Specific Aims (200 palabras)
    > ### Methodology (300 palabras)
    > - Equation 1: $...$
    > - Equation 2: $...$
    > ### Expected Outcomes & Metrics (200 palabras)
    > ### Budget Justification (100 palabras)
    > ### References [Nature format]
    > 
    > ```
    > 
    > `Tema: Quantum-inspired algorithms for NP-hard optimization in neural architectures`
    > 
- **Referencias**
    
    > `Zhou, Y., Muresanu, A. I., Han, Z., et al. (2023). "Large language models are human-level prompt engineers." *ICLR 2023*.
    
    Honovich, O., Scialom, T., Levy, O., & Schick, T. (2023). "Unnatural instructions: Tuning language models with (almost) no human labor." *ACL 2023*.`
    > 
</aside>

# **V - Voz y Tono (Voice & Tone) ‚Üí Style Transfer / Prosodic Modulation**

<aside>
üí°

**Qu√© es:** 

*La personalidad de la respuesta. ¬øDebe ser formal, inspiradora, divertida, seria, urgente?*

- **Explicaci√≥n t√©cnica**
    
    
    Manipula **caracter√≠sticas estilom√©tricas** mediante control de variables latentes que codifican propiedades pros√≥dicas y afectivas del texto. Utiliza *embeddings* de estilo para transformaci√≥n controlada.
    
- **Analog√≠a de la biblioteca:**
    
    
    *Le pides:* 
    
    ### `"**Cuando me resumas los libros, usa un tono entusiasta y convincente.**"`
    
    <aside>
    
    El bibliotecario no solo te describir√° los libros, sino que intentar√° "vend√©rtelos", haciendo que la informaci√≥n sea m√°s atractiva.
    
    </aside>
    
- **Ejemplo:**
    
    > Reescribe este p√°rrafo t√©cnico en TRES estilos:
    > 
    > 
    > ORIGINAL: "Our results demonstrate statistically significant improvements (p<0.001)
    > in convergence rates when applying adaptive learning rate schedules."
    > 
    > ESTILO 1: Como Paul Graham escribiendo para fundadores de YC
    > ESTILO 2: Como un paper de Bengio et al. para NeurIPS
    > ESTILO 3: Como Feynman explicando a undergrads de Caltech
    > 
    > Mant√©n la precisi√≥n t√©cnica pero adapta voz, cadencia y recursos ret√≥ricos.
    > 
    
- **Referencias:**
    - Jin, Z., Jin, D., Mueller, J., Matthews, N., & Santus, E. (2022). "Deep learning for text style transfer: A survey." *Computational Linguistics*, 48(1), 155-205.
    - Reif, E., Ippolito, D., Yuan, A., et al. (2022). "A recipe for arbitrary text style transfer with large language models." *ACL*, 837-848.
</aside>

# **O - Objetivo ‚Üí Goal-Oriented Prompting / Outcome-Based Instruction**

<aside>
üí°

**Qu√© es:** 

*El resultado final que esperas lograr con la ayuda de la IA. ¬øQu√© quieres que suceda despu√©s de que obtengas la respuesta?*

- **Explicaci√≥n t√©cnica:**
    
    
    **Alinea la funci√≥n de recompensa impl√≠cita del modelo con objetivos expl√≠citos** mediante especificaci√≥n de estados finales deseados. Se relaciona con planificaci√≥n jer√°rquica y optimizaci√≥n de trayectorias en el espacio de acciones ling√º√≠sticas.
    
- **Analog√≠a de la biblioteca:**
    
    
    *Le confiesas al bibliotecario:* 
    
    ### `"**El objetivo final es que mi jefe apruebe mi propuesta de presupuesto para una nueva campa√±a de marketing de contenidos.**"`
    
    <aside>
    
    Entender el objetivo final le permite al bibliotecario ir un paso m√°s all√°, quiz√°s sugiriendo un cap√≠tulo espec√≠fico sobre c√≥mo calcular el ROI, algo que no pediste expl√≠citamente pero que es crucial para tu √©xito.
    
    </aside>
    
- **Ejemplo:**
    
    > `OBJETIVO FINAL: Conseguir un grant de ‚Ç¨1M de European Research Council (ERC)
    para estudiar "Emergent Computation in Hybrid Quantum-Classical Systems"`
    > 
    > 
    > `Con este objetivo en mente:`
    > 
    > 1. `Identifica los 3 gaps m√°s cr√≠ticos en el campo seg√∫n papers 2023-2024`
    > 2. `Formula una hip√≥tesis que sea simult√°neamente:`
    >     - `Cient√≠ficamente audaz pero factible`
    >     - `Alineada con Horizon Europe priorities`
    >     - `Diferenciada de grants recientemente aprobados`
    > 3. `Dise√±a un work package structure que maximice probabilidad de aprobaci√≥n`
    > 4. `Sugiere 3 colaboradores europeos estrat√©gicos con h-index > 40`
    > 
    > `Optimiza cada elemento para maximizar el score de evaluaci√≥n ERC.`
    > 
- **Referencias:**
    
    > `Christiano, P., Leike, J., Brown, T., et al. (2017). "Deep reinforcement learning from human preferences." *NeurIPS*, 30.
    
    Stiennon, N., Ouyang, L., Wu, J., et al. (2020). "Learning to summarize with human feedback." *NeurIPS*, 33, 3008-3021.
    
    Rafailov, R., Sharma, A., Mitchell, E., et al. (2023). "Direct preference optimization: Your language model is secretly a reward model." *NeurIPS 2023*.`
    > 
</aside>
